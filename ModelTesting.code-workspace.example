{
  "folders": [
    {
      "path": ".",
      "name": "Cloudera Inference With CursorAI"
    }
  ],
  "settings": {
    "files.exclude": {
      "**/.git": true,
      "**/.DS_Store": true,
      "**/__pycache__": true,
      "**/*.pyc": true,
      "**/venv": true
    },
    "files.associations": {
      "*.sh": "shellscript"
    },
    "editor.formatOnSave": true,
    "editor.defaultFormatter": "ms-python.python",
    "[shellscript]": {
      "editor.defaultFormatter": "mkhl.shfmt",
      "editor.formatOnSave": true
    },
    "[python]": {
      "editor.defaultFormatter": "ms-python.python",
      "editor.formatOnSave": true
    },
    "files.eol": "\n",
    "files.insertFinalNewline": true,
    "files.trimTrailingWhitespace": true,
    "python.defaultInterpreterPath": "${workspaceFolder}/venv/bin/python",
    "python.terminal.activateEnvironment": true,
    "cursor.ai.enabled": true,
    "cursor.ai.provider": "custom",
    "cursor.ai.customEndpoint": {
      "baseUrl": "https://your-cloudera-endpoint.com/namespaces/serving-default/endpoints/your-endpoint-name/v1",
      "apiKey": "YOUR_API_KEY_HERE",
      "model": "nvidia/llama-3.3-nemotron-super-49b-v1"
    },
    "cursor.ai.openai.enabled": false,
    "cursor.ai.anthropic.enabled": false
  },
  "extensions": {
    "recommendations": [
      "mkhl.shfmt",
      "timonwong.shellcheck",
      "ms-python.python",
      "ms-python.vscode-pylance"
    ]
  }
}

